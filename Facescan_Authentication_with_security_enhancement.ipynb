{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# this notebook contains code which is trianable"
      ],
      "metadata": {
        "id": "bFAMhyGdzKdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHSMzlLMZ2k",
        "outputId": "73b1af1b-8604-4788-d1fe-17c14cffb8a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# initial processing"
      ],
      "metadata": {
        "id": "xvdKDgu_QbFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pipeline starts"
      ],
      "metadata": {
        "id": "N7mM_BYBH8cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install DeepFace\n"
      ],
      "metadata": {
        "id": "i6zlx5GlSXSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb3422d4-97dd-46d7-8bbe-36e11c609ded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting DeepFace\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (2.1.4)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (5.1.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (4.66.5)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (9.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (4.10.0.84)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (2.17.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (3.4.1)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from DeepFace) (2.2.5)\n",
            "Collecting flask-cors>=4.0.1 (from DeepFace)\n",
            "  Downloading Flask_Cors-5.0.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting mtcnn>=0.1.0 (from DeepFace)\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from DeepFace)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from DeepFace)\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from DeepFace)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->DeepFace) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.4.0->DeepFace) (2.4.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->DeepFace) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->DeepFace) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->DeepFace) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=1.1.2->DeepFace) (8.1.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->DeepFace) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown>=3.10.1->DeepFace) (3.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gunicorn>=20.1.0->DeepFace) (24.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (13.8.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=2.2.0->DeepFace) (0.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->DeepFace) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->DeepFace) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->DeepFace) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->DeepFace) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->DeepFace) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->DeepFace) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.27.1->DeepFace) (2024.8.30)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=1.9.0->DeepFace) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->DeepFace) (0.44.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=1.1.2->DeepFace) (2.1.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->DeepFace) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=1.9.0->DeepFace) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=3.10.1->DeepFace) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=3.10.1->DeepFace) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->DeepFace) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=2.2.0->DeepFace) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->DeepFace) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Flask_Cors-5.0.0-py2.py3-none-any.whl (14 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=076dc00c96718e6551ed1ffbac77b22edea24356e8f8e4530ddb779aea8c92fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built fire\n",
            "Installing collected packages: gunicorn, fire, flask-cors, mtcnn, retina-face, DeepFace\n",
            "Successfully installed DeepFace-0.0.93 fire-0.6.0 flask-cors-5.0.0 gunicorn-23.0.0 mtcnn-0.1.1 retina-face-0.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from deepface import DeepFace\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "OZ57wIOpHePH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80c35d9-7486-456f-8575-3b752e8b6f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24-09-12 07:31:54 - Directory /root/.deepface has been created\n",
            "24-09-12 07:31:54 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from retinaface import RetinaFace\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Function to calculate brightness\n",
        "def calculate_brightness(img):\n",
        "    return np.mean(cv2.cvtColor(img, cv2.COLOR_BGR2HSV)[:,:,2])\n",
        "\n",
        "# Function to calculate contrast\n",
        "def calculate_contrast(img):\n",
        "    return img.std()\n",
        "\n",
        "# Function to calculate noise\n",
        "def calculate_noise(img):\n",
        "    return np.var(img)\n",
        "\n",
        "# Function to calculate sharpness using Laplacian\n",
        "def calculate_sharpness(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
        "\n",
        "# Function to calculate the alignment of the face\n",
        "def calculate_alignment(landmarks):\n",
        "    left_eye = np.array(landmarks['left_eye'])\n",
        "    right_eye = np.array(landmarks['right_eye'])\n",
        "    delta_y = right_eye[1] - left_eye[1]\n",
        "    delta_x = right_eye[0] - left_eye[0]\n",
        "    angle = np.degrees(np.arctan2(delta_y, delta_x))\n",
        "    return abs(angle)\n",
        "\n",
        "# Function to check if the eyes, nose, and ears are parallel\n",
        "def are_features_parallel(face_info):\n",
        "    landmarks = face_info['landmarks']\n",
        "    eye_left = landmarks['left_eye']\n",
        "    eye_right = landmarks['right_eye']\n",
        "    nose = landmarks['nose']\n",
        "    ear_left = landmarks.get('left_ear', None)\n",
        "    ear_right = landmarks.get('right_ear', None)\n",
        "\n",
        "    # Check if eyes are parallel (difference in y-coordinates should be minimal)\n",
        "    eyes_parallel = abs(eye_left[1] - eye_right[1]) < 20  # Increased tolerance\n",
        "\n",
        "    # Check if nose is centered between the eyes\n",
        "    nose_centered = abs(nose[0] - (eye_left[0] + eye_right[0]) / 2) < 20  # Increased tolerance\n",
        "\n",
        "    # Check if ears are parallel (optional, depends on availability)\n",
        "    ears_parallel = True\n",
        "    if ear_left is not None and ear_right is not None:\n",
        "        ears_parallel = abs(ear_left[1] - ear_right[1]) < 20  # Increased tolerance\n",
        "\n",
        "    return eyes_parallel and nose_centered and ears_parallel\n",
        "\n",
        "# Function to process images from a folder\n",
        "def process_images(input_folder, output_folder, threshold_values):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(input_folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Detect faces using RetinaFace\n",
        "            faces = RetinaFace.detect_faces(img)\n",
        "\n",
        "            if isinstance(faces, dict):\n",
        "                for face_id, face_info in faces.items():\n",
        "                    x1, y1, x2, y2 = face_info['facial_area']\n",
        "                    face_img = img[y1:y2, x1:x2]  # Crop the face\n",
        "\n",
        "                    # Calculate features on the cropped face\n",
        "                    brightness = calculate_brightness(face_img)\n",
        "                    contrast = calculate_contrast(face_img)\n",
        "                    noise = calculate_noise(face_img)\n",
        "                    # sharpness = calculate_sharpness(face_img)\n",
        "                    alignment = calculate_alignment(face_info['landmarks'])\n",
        "\n",
        "                    print(f'Processing {filename} - Brightness: {brightness}, Contrast: {contrast}, Noise: {noise}, Sharpness: {sharpness}, Alignment Angle: {alignment}')\n",
        "\n",
        "                    # Apply thresholds\n",
        "                    if (brightness > threshold_values['brightness'] and\n",
        "                        contrast < threshold_values['contrast'] and\n",
        "                        noise < threshold_values['noise'] and\n",
        "                        # sharpness > threshold_values['sharpness'] and\n",
        "                        alignment < threshold_values['alignment']):\n",
        "\n",
        "                        if are_features_parallel(face_info):\n",
        "                            # Save the accepted face image\n",
        "                            output_path = os.path.join(output_folder, filename)\n",
        "                            cv2.imwrite(output_path, face_img)\n",
        "                            print(f'Image {filename} accepted and saved to {output_path}')\n",
        "                        else:\n",
        "                            print(f'Image {filename} rejected due to misaligned facial features')\n",
        "                    else:\n",
        "                        print(f'Image {filename} rejected due to low quality features or poor alignment')\n",
        "\n",
        "# Define threshold values\n",
        "threshold_values = {\n",
        "    'brightness': 100,\n",
        "    'contrast': 60,\n",
        "    'noise': 3500,\n",
        "    # 'sharpness': 150,  # Adjusted based on the Laplacian variance scale\n",
        "    'alignment': 180\n",
        "}\n",
        "\n",
        "# Process images in a folder\n",
        "input_folder = '/content/drive/My Drive/dataset_train'\n",
        "output_folder = '/content/drive/My Drive/Cropped_Faces'\n",
        "process_images(input_folder, output_folder, threshold_values)\n"
      ],
      "metadata": {
        "id": "ngSOvKFj0acs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a directory with images organized in subfolders for each class\n",
        "dir = '/content/drive/My Drive/Cropped_Faces'\n",
        "imgfolders = [os.path.join(dir, folder) for folder in os.listdir(dir)]\n",
        "# List to store paths of all images\n",
        "imgpaths = []\n",
        "for folder in imgfolders:\n",
        "    for path in os.listdir(folder):\n",
        "        imgpaths.append(os.path.join(folder, path))"
      ],
      "metadata": {
        "id": "hUOCgWZhIa14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJREIqW-Xdxz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6cd918-98cd-4f68-9a07-20c39022aa1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of all_embeddings: (22, 512)\n",
            "torch.Size([1, 1, 512]) tensor([1])\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from deepface import DeepFace\n",
        "import os\n",
        "\n",
        "def normalize_brightness_contrast_grayscale(image):\n",
        "    # Normalize brightness using LAB color space\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    l = cv2.equalizeHist(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Contrast normalization using CLAHE\n",
        "    lab = cv2.cvtColor(normalized_image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_contrast_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(normalized_contrast_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return gray_image\n",
        "\n",
        "def get_all_embeddings(img_paths, save_directory=\"/content/drive/MyDrive/D9\"):\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_directory, exist_ok=True)\n",
        "\n",
        "    embeddings = []\n",
        "    for img_path in img_paths:\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        # Normalize brightness, contrast, and convert to grayscale\n",
        "        processed_image = normalize_brightness_contrast_grayscale(image)\n",
        "\n",
        "        # Generate a new filename\n",
        "        base_name = os.path.basename(img_path)\n",
        "        name, ext = os.path.splitext(base_name)\n",
        "        processed_image_path = os.path.join(save_directory, f\"{name}_processed{ext}\")\n",
        "\n",
        "\n",
        "        # Save the processed image\n",
        "        cv2.imwrite(processed_image_path, processed_image)\n",
        "\n",
        "        embedding = DeepFace.represent(img_path=processed_image_path, model_name=\"Facenet512\", detector_backend='skip')\n",
        "        embarr = np.array(embedding[0][\"embedding\"])\n",
        "        embeddings.append(embarr)\n",
        "\n",
        "\n",
        "    return np.array(embeddings)\n",
        "\n",
        "all_embeddings = get_all_embeddings(imgpaths)\n",
        "print(\"Shape of all_embeddings:\", all_embeddings.shape)  # Should be (num_images, 512)\n",
        "\n",
        "# Convert embeddings to PyTorch tensors\n",
        "X = torch.tensor(all_embeddings, dtype=torch.float32)\n",
        "\n",
        "# Assuming you have ground truth labels for each image class\n",
        "######################################################################################################3\n",
        "# Here, creating dummy labels assuming 5 classes  now 9 classes  now 12 classses    now 20 classes                      ## if there is any change in no of clssses append thghis\n",
        "########################################################################################################################\n",
        "#y = torch.tensor([i // (len(X) // 20) for i in range(len(X))], dtype=torch.long)  # Adjust as per your dataset\n",
        "\n",
        "# Assuming you have 20 classes and 8 images per class\n",
        "num_classes = 2\n",
        "images_per_class = 11\n",
        "\n",
        "# Generate labels\n",
        "y = torch.tensor([i // images_per_class for i in range(num_classes * images_per_class)], dtype=torch.long)\n",
        "\n",
        "\n",
        "# Custom Dataset class\n",
        "class EmbeddingsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx].unsqueeze(0), self.y[idx]  # Add sequence dimension\n",
        "\n",
        "\n",
        "# Create DataLoader\n",
        "dataset = EmbeddingsDataset(X, y)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# Check the DataLoader\n",
        "for data in dataloader:\n",
        "    inputs, labels = data\n",
        "    print(inputs.shape, labels)\n",
        "    break  # Print one batch and break to avoid clutter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save embeddings and labels using torch\n",
        "save_path = '/content/drive/MyDrive/emb_D9'\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "torch.save(X, os.path.join(save_path, 'all_embeddings.pt'))\n",
        "torch.save(y, os.path.join(save_path, 'labels.pt'))\n",
        "\n",
        "print(\"Embeddings and labels saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45eC4CRHImJy",
        "outputId": "30b140d7-7841-4aeb-9700-8b6fe76e3444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embeddings and labels saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvU-ux42I2CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zCrtwXdsI1-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N9R7jVRFI15A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load embeddings and labels using torch\n",
        "save_path = '/content/drive/MyDrive/emb_with_prep/Model_weights And Embeddings'\n",
        "loaded_embeddings = torch.load(os.path.join(save_path, 'all_embeddings.pt'))\n",
        "loaded_labels = torch.load(os.path.join(save_path, 'labels.pt'))\n",
        "X = loaded_embeddings\n",
        "y = loaded_labels\n",
        "\n",
        "print(\"Loaded embeddings shape:\", loaded_embeddings.shape)  # Should be (num_images, 512)\n",
        "print(\"Loaded labels shape:\", loaded_labels.shape)  # Should match the number of images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfpKmseGIr0H",
        "outputId": "03b806db-b95d-43aa-c392-28fe39810f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded embeddings shape: torch.Size([460, 512])\n",
            "Loaded labels shape: torch.Size([460])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HgHxhbZIrxj",
        "outputId": "e0eadca9-ce82-404e-b08a-3e4d7b4ac66c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([460])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nRY3TJOiVvq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2GP18HWfVvm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bKhgcCx8Vvho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# teacher student model"
      ],
      "metadata": {
        "id": "avYxzrGRVmbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the teacher model is pre-trained on 23 classes\n",
        "teacher_model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers)\n",
        "teacher_model.load_state_dict(torch.load(\"/content/drive/MyDrive/pretrained_teacher_model.pth\"))  # Path to the pre-trained model\n",
        "teacher_model.eval()  # Set the model to evaluation mode\n"
      ],
      "metadata": {
        "id": "na4v0fx4VmE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yPKJMdMhVmCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JkwEhZRIVl_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iJ3EPSoVl8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Prgucev4Vl3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yRpDq6HaVl0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HH5PRvwPVlx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # @title\n",
        "# # Custom Dataset class\n",
        "# class EmbeddingsDataset(Dataset):\n",
        "#     def __init__(self, X, y):\n",
        "#         self.X = X\n",
        "#         self.y = y\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.y)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.X[idx].unsqueeze(0), self.y[idx]  # Add sequence dimension\n",
        "\n",
        "# # Create DataLoader\n",
        "# dataset = EmbeddingsDataset(X, y)\n",
        "# dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# # Check the DataLoader\n",
        "# for data in dataloader:\n",
        "#     inputs, labels = data\n",
        "#     print(inputs.shape, labels)\n",
        "#     break  # Print one batch and break to avoid clutter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL4iF3EtK-s5",
        "outputId": "405469c1-10a9-473a-89b8-84e7e8bbaba8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 512]) tensor([7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "\n",
        "class BiLSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # Multiply by 2 because of bidirection\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Pack the sequence\n",
        "        packed_input = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, (hn, _) = self.lstm(packed_input)\n",
        "\n",
        "        # Concatenate the forward and backward hidden states\n",
        "        out = self.fc(torch.cat((hn[-2], hn[-1]), dim=1))  # Take the last hidden state from both directions\n",
        "        return out\n",
        "\n",
        "# Model parameters\n",
        "input_dim = 512  # Dimension of the Facenet512 embeddings\n",
        "hidden_dim = 256\n",
        "output_dim = 128  # Output dimension of the LSTM\n",
        "num_layers = 4  # Number of LSTM layers\n",
        "\n",
        "# Instantiate the BiLSTM model\n",
        "model = BiLSTMModel(input_dim, hidden_dim, output_dim, num_layers)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "xNZYZiU1Istl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model with output dimension 128\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # Pack the sequence\n",
        "        packed_input = rnn_utils.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_output, (hn, _) = self.lstm(packed_input)\n",
        "        # We only need the last hidden state\n",
        "        out = self.fc(hn[-1])\n",
        "        return out\n",
        "\n",
        "# Model parameters\n",
        "input_dim = 512  # Dimension of the Facenet512 embeddings\n",
        "hidden_dim = 256\n",
        "output_dim = 128  # Output dimension of the LSTM\n",
        "num_layers = 4  # Number of LSTM layers\n",
        "\n",
        "# Instantiate the model\n",
        "model = LSTMModel(input_dim, hidden_dim, output_dim, num_layers)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "R8dObKDYK-lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "# Training loop\n",
        "\n",
        "# List to store loss values\n",
        "losses = []\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    for inputs, labels in dataloader:\n",
        "        # Get the lengths of sequences\n",
        "        lengths = torch.tensor([inputs.shape[1]])  # Assuming all sequences have the same length\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs, lengths)\n",
        "        loss = criterion(outputs, labels)\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    losses.append(avg_loss)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
        "\n",
        "# Plot the loss curve\n",
        "plt.plot(range(1, num_epochs+1), losses, marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Curve')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "XGLfbaOoK-iW",
        "outputId": "39807bd8-b00c-443e-94d4-9a683479e18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.4577\n",
            "Epoch [2/20], Loss: 0.7904\n",
            "Epoch [3/20], Loss: 0.3631\n",
            "Epoch [4/20], Loss: 0.0413\n",
            "Epoch [5/20], Loss: 0.0075\n",
            "Epoch [6/20], Loss: 0.0037\n",
            "Epoch [7/20], Loss: 0.0022\n",
            "Epoch [8/20], Loss: 0.0015\n",
            "Epoch [9/20], Loss: 0.0010\n",
            "Epoch [10/20], Loss: 0.0007\n",
            "Epoch [11/20], Loss: 0.0005\n",
            "Epoch [12/20], Loss: 0.0004\n",
            "Epoch [13/20], Loss: 0.0003\n",
            "Epoch [14/20], Loss: 0.0002\n",
            "Epoch [15/20], Loss: 0.0002\n",
            "Epoch [16/20], Loss: 0.0001\n",
            "Epoch [17/20], Loss: 0.0001\n",
            "Epoch [18/20], Loss: 0.0001\n",
            "Epoch [19/20], Loss: 0.0001\n",
            "Epoch [20/20], Loss: 0.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_no_aug_path = '/content/drive/MyDrive/emb_D9/lstm_no_prep.pth'  # Adjust the path as needed\n",
        "torch.save(model.state_dict(), lstm_no_aug_path)\n",
        "\n",
        "#torch.save(model.state_dict(), 'lstm_model_128.pth')"
      ],
      "metadata": {
        "id": "X-BL9LyAK-fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7D9lHb27M1qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uh7dBdOuM1js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "slJ5V_-NM1g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_no_aug_path = '/content/drive/MyDrive/bilstm_no_prep.pth'  # Adjust the path as needed\n",
        "torch.save(model.state_dict(), lstm_no_aug_path)\n"
      ],
      "metadata": {
        "id": "-NlfqNCvJjwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import cv2\n",
        "# from deepface import DeepFace\n",
        "# import matplotlib.pyplot as plt\n",
        "# from collections import defaultdict\n",
        "\n",
        "# # Block 1: Code for Loading Class Embeddings and Rounding Off\n",
        "# model.load_state_dict(torch.load(lstm_no_aug_path))\n",
        "# model.eval()\n",
        "\n",
        "# def get_lengths(batch_size):\n",
        "#     return torch.ones(batch_size, dtype=torch.long)\n",
        "\n",
        "# class_vectors = defaultdict(list)\n",
        "# with torch.no_grad():\n",
        "#     for inputs, labels in dataloader:\n",
        "#         lengths = get_lengths(inputs.size(0))  # Get lengths for the current batch\n",
        "#         class_vector = model(inputs, lengths)\n",
        "#         class_vectors[labels.item()].append(class_vector.squeeze().numpy())\n",
        "\n",
        "# rounded_class_vectors = {class_num: [np.round(vector, 0) for vector in vectors] for class_num, vectors in class_vectors.items()}\n",
        "\n",
        "# save_dir = 'path/to/save/embeddings'\n",
        "# if not os.path.exists(save_dir):\n",
        "#     os.makedirs(save_dir)\n",
        "\n",
        "# for class_num, vectors in rounded_class_vectors.items():\n",
        "#     for idx, vector in enumerate(vectors):\n",
        "#         np.save(os.path.join(save_dir, f'class_{class_num}_vector_{idx}.npy'), vector)\n",
        "\n",
        "# # Block 2: Code for Getting Image Embedding without Preprocessing\n",
        "# def get_initial_image_embedding(image_path):\n",
        "#     embedding = DeepFace.represent(img_path=image_path, model_name=\"Facenet512\", detector_backend='skip')\n",
        "#     embarr = np.array(embedding[0][\"embedding\"])\n",
        "#     return torch.tensor(embarr, dtype=torch.float32).unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "# def get_final_image_embedding(image_path, model):\n",
        "#     initial_embedding = get_initial_image_embedding(image_path)\n",
        "#     lengths = torch.tensor([initial_embedding.shape[1]]) # Sequence length is 1\n",
        "#     with torch.no_grad():\n",
        "#         final_embedding = model(initial_embedding, lengths)\n",
        "#     return final_embedding\n",
        "\n",
        "# # Block 3: Code for Comparing New Image Embedding\n",
        "# def load_all_embeddings(save_dir):\n",
        "#     all_embeddings = defaultdict(list)\n",
        "#     for file in os.listdir(save_dir):\n",
        "#         if file.endswith('.npy'):\n",
        "#             class_num = int(file.split('_')[1])\n",
        "#             vector = np.load(os.path.join(save_dir, file))\n",
        "#             all_embeddings[class_num].append(torch.tensor(vector, dtype=torch.float32))\n",
        "#     return all_embeddings\n",
        "\n",
        "# def compare_with_tolerance(embedding1, embedding2, tolerance=0.1):\n",
        "#     return torch.sum(torch.abs(embedding1 - embedding2) <= tolerance).item()\n",
        "\n",
        "# def compare_new_image(image_path, model, save_dir, tolerance=0.1):\n",
        "#     new_image_final_embedding = get_final_image_embedding(image_path, model)\n",
        "#     all_embeddings = load_all_embeddings(save_dir)\n",
        "\n",
        "#     new_image_final_embedding_rounded = torch.round(new_image_final_embedding)\n",
        "\n",
        "#     print(f\"New Image Embedding:\\n{new_image_final_embedding_rounded.squeeze().numpy()}\")\n",
        "\n",
        "#     for class_num, vectors in all_embeddings.items():\n",
        "#         print(f\"\\nClass {class_num}:\")\n",
        "\n",
        "#         # Print comparisons between new image embedding and each vector in the class\n",
        "#         for i, vector in enumerate(vectors):\n",
        "#             vector_rounded = torch.round(vector)\n",
        "#             matching_count = compare_with_tolerance(new_image_final_embedding_rounded, vector_rounded, tolerance)\n",
        "#             print(f\"Comparison with Class {class_num} Vector {i}: {matching_count} matching values\")\n",
        "\n",
        "#     # Optionally plot comparisons for visual inspection\n",
        "#     # for class_num, vectors in all_embeddings.items():\n",
        "#     #     for i, vector in enumerate(vectors):\n",
        "#     #         plt.figure(figsize=(10, 6))\n",
        "#     #         plt.plot(range(128), vector.numpy(), label=f'Class {class_num} Vector {i}')\n",
        "#     #         plt.plot(range(128), new_image_final_embedding_rounded.squeeze().numpy(), label='New Image Embedding')\n",
        "#     #         plt.xlabel('Index')\n",
        "#     #         plt.ylabel('Value')\n",
        "#     #         plt.title(f'Comparison of Class {class_num} Vector {i} and New Image Embedding')\n",
        "#     #         plt.legend()\n",
        "#     #         plt.show()\n",
        "\n",
        "# # Test with a new image\n",
        "# new_image_path = '/content/drive/MyDrive/FaceScan_D8_no_bg2/Test/Ajay/20240826_181953.jpg'\n",
        "# compare_new_image(new_image_path, model, save_dir)\n"
      ],
      "metadata": {
        "id": "OIRISYGfLKkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove bg in test image"
      ],
      "metadata": {
        "id": "jWUWj6EeGOpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from retinaface import RetinaFace\n",
        "def crop_faces(image_path, output_folder):\n",
        "    # Load the image\n",
        "    img = cv2.imread(image_path)\n",
        "    # Detect faces\n",
        "    faces = RetinaFace.detect_faces(image_path)\n",
        "\n",
        "    if faces:\n",
        "        for i, face in enumerate(faces.values()):\n",
        "            facial_area = face['facial_area']\n",
        "            # Crop face from the image\n",
        "            cropped_face = img[facial_area[1]:facial_area[3], facial_area[0]:facial_area[2]]\n",
        "            # Save cropped face\n",
        "            output_path = os.path.join(output_folder, f'face_{i}.jpg')\n",
        "            cv2.imwrite(output_path, cropped_face)\n",
        "def process_folders(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for folder_name in os.listdir(input_folder):\n",
        "        folder_path = os.path.join(input_folder, folder_name)\n",
        "        output_subfolder = os.path.join(output_folder, folder_name)\n",
        "\n",
        "        if not os.path.exists(output_subfolder):\n",
        "            os.makedirs(output_subfolder)\n",
        "\n",
        "        if os.path.isdir(folder_path):\n",
        "            for file_name in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, file_name)\n",
        "                if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    crop_faces(file_path, output_subfolder)\n",
        "input_folder = '/content/drive/MyDrive/New_test'  #input raw test image\n",
        "output_folder = '/content/drive/MyDrive/New_test_cropped' #saved after retinaface cropped image\n",
        "\n",
        "process_folders(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "8L4khboxGOSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTKcRlr6GOQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_brightness_contrast_grayscale(image):\n",
        "    # Normalize brightness using LAB color space\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    l = cv2.equalizeHist(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Contrast normalization using CLAHE\n",
        "    lab = cv2.cvtColor(normalized_image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_contrast_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(normalized_contrast_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return gray_image"
      ],
      "metadata": {
        "id": "HkHZuOLILKh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict  # Add this import\n",
        "\n",
        "# Block 1: Code for Loading Class Embeddings and Rounding Off\n",
        "model.load_state_dict(torch.load(lstm_no_aug_path))\n",
        "model.eval()\n",
        "\n",
        "def get_lengths(batch_size):\n",
        "    return torch.ones(batch_size, dtype=torch.long)\n",
        "\n",
        "class_vectors = defaultdict(list)\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in dataloader:\n",
        "        lengths = get_lengths(inputs.size(0))  # Get lengths for the current batch\n",
        "        class_vector = model(inputs, lengths)\n",
        "        class_vectors[labels.item()].append(class_vector.squeeze().numpy())\n",
        "\n",
        "rounded_class_vectors = {class_num: [np.round(vector, 0) for vector in vectors] for class_num, vectors in class_vectors.items()}\n",
        "\n",
        "save_dir = 'path1/to/save/embeddings'\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "for class_num, vectors in rounded_class_vectors.items():\n",
        "    for idx, vector in enumerate(vectors):\n",
        "        np.save(os.path.join(save_dir, f'class_{class_num}_vector_{idx}.npy'), vector)\n",
        "\n",
        "# Block 2: Code for Getting Image Embedding\n",
        "def get_initial_image_embedding(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if len(image.shape) == 2:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    processed_image = normalize_brightness_contrast_grayscale(image)\n",
        "    if len(processed_image.shape) == 2:\n",
        "        processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)\n",
        "    embedding = DeepFace.represent(img_path=processed_image, model_name=\"Facenet512\", detector_backend='skip')\n",
        "    embarr = np.array(embedding[0][\"embedding\"])\n",
        "    return torch.tensor(embarr, dtype=torch.float32).unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "def get_final_image_embedding(image_path, model):\n",
        "    initial_embedding = get_initial_image_embedding(image_path)\n",
        "    lengths = torch.tensor([initial_embedding.shape[1]])  # Sequence length is 1\n",
        "    with torch.no_grad():\n",
        "        final_embedding = model(initial_embedding, lengths)\n",
        "    return final_embedding\n",
        "\n",
        "# Block 3: Code for Comparing New Image Embedding\n",
        "def load_all_embeddings(save_dir):\n",
        "    all_embeddings = defaultdict(list)\n",
        "    for file in os.listdir(save_dir):\n",
        "        if file.endswith('.npy'):\n",
        "            class_num = int(file.split('_')[1])\n",
        "            vector = np.load(os.path.join(save_dir, file))\n",
        "            all_embeddings[class_num].append(torch.tensor(vector, dtype=torch.float32))\n",
        "    return all_embeddings\n",
        "\n",
        "def compare_with_tolerance(embedding1, embedding2, tolerance=0.1):\n",
        "    return torch.sum(torch.abs(embedding1 - embedding2) <= tolerance).item()\n",
        "\n",
        "def compare_new_image(image_path, model, save_dir, tolerance=0.1):\n",
        "    new_image_final_embedding = get_final_image_embedding(image_path, model)\n",
        "    all_embeddings = load_all_embeddings(save_dir)\n",
        "\n",
        "    new_image_final_embedding_rounded = torch.round(new_image_final_embedding)\n",
        "\n",
        "    print(f\"New Image Embedding:\\n{new_image_final_embedding_rounded.squeeze().numpy()}\")\n",
        "\n",
        "    for class_num, vectors in all_embeddings.items():\n",
        "        print(f\"\\nClass {class_num}:\")\n",
        "\n",
        "        # Print comparisons between new image embedding and each vector in the class\n",
        "        for i, vector in enumerate(vectors):\n",
        "            vector_rounded = torch.round(vector)\n",
        "            matching_count = compare_with_tolerance(new_image_final_embedding_rounded, vector_rounded, tolerance)\n",
        "            print(f\"Comparison with Class {class_num} Vector {i}: {matching_count} matching values\")\n",
        "# Test with a new image\n",
        "new_image_path = '/content/drive/MyDrive/28thnight/FaceScan_D8_no_bg2/Test/Lab3/IMG_20240821_150911746_HDR.jpg'\n",
        "compare_new_image(new_image_path, model, save_dir)\n"
      ],
      "metadata": {
        "id": "TSpucF1pLKfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ace9dea-162d-42ed-f317-ff5f23031eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Image Embedding:\n",
            "[-0.  7. -0. -1. -1. -1. -1. -0. -1. 19.  3. -0.  5. -4. -3.  7.  0.  5.\n",
            " -1.  1. -3.  4. -1.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.  0.  0.  0.\n",
            "  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0. -0.  0. -0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0. -0.  0.  0.  0.  0.  0.\n",
            "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -0.\n",
            "  0.  0.]\n",
            "\n",
            "Class 20:\n",
            "Comparison with Class 20 Vector 0: 0 matching values\n",
            "Comparison with Class 20 Vector 1: 0 matching values\n",
            "Comparison with Class 20 Vector 2: 0 matching values\n",
            "Comparison with Class 20 Vector 3: 0 matching values\n",
            "Comparison with Class 20 Vector 4: 0 matching values\n",
            "Comparison with Class 20 Vector 5: 0 matching values\n",
            "Comparison with Class 20 Vector 6: 0 matching values\n",
            "Comparison with Class 20 Vector 7: 0 matching values\n",
            "Comparison with Class 20 Vector 8: 0 matching values\n",
            "Comparison with Class 20 Vector 9: 0 matching values\n",
            "Comparison with Class 20 Vector 10: 0 matching values\n",
            "Comparison with Class 20 Vector 11: 0 matching values\n",
            "Comparison with Class 20 Vector 12: 0 matching values\n",
            "Comparison with Class 20 Vector 13: 0 matching values\n",
            "Comparison with Class 20 Vector 14: 0 matching values\n",
            "Comparison with Class 20 Vector 15: 0 matching values\n",
            "Comparison with Class 20 Vector 16: 0 matching values\n",
            "Comparison with Class 20 Vector 17: 0 matching values\n",
            "Comparison with Class 20 Vector 18: 0 matching values\n",
            "Comparison with Class 20 Vector 19: 0 matching values\n",
            "\n",
            "Class 13:\n",
            "Comparison with Class 13 Vector 0: 2 matching values\n",
            "Comparison with Class 13 Vector 1: 2 matching values\n",
            "Comparison with Class 13 Vector 2: 2 matching values\n",
            "Comparison with Class 13 Vector 3: 2 matching values\n",
            "Comparison with Class 13 Vector 4: 2 matching values\n",
            "Comparison with Class 13 Vector 5: 2 matching values\n",
            "Comparison with Class 13 Vector 6: 2 matching values\n",
            "Comparison with Class 13 Vector 7: 2 matching values\n",
            "Comparison with Class 13 Vector 8: 2 matching values\n",
            "Comparison with Class 13 Vector 9: 2 matching values\n",
            "Comparison with Class 13 Vector 10: 2 matching values\n",
            "Comparison with Class 13 Vector 11: 2 matching values\n",
            "Comparison with Class 13 Vector 12: 2 matching values\n",
            "Comparison with Class 13 Vector 13: 2 matching values\n",
            "Comparison with Class 13 Vector 14: 2 matching values\n",
            "Comparison with Class 13 Vector 15: 2 matching values\n",
            "Comparison with Class 13 Vector 16: 2 matching values\n",
            "Comparison with Class 13 Vector 17: 2 matching values\n",
            "Comparison with Class 13 Vector 18: 2 matching values\n",
            "Comparison with Class 13 Vector 19: 2 matching values\n",
            "\n",
            "Class 12:\n",
            "Comparison with Class 12 Vector 0: 3 matching values\n",
            "Comparison with Class 12 Vector 1: 3 matching values\n",
            "Comparison with Class 12 Vector 2: 3 matching values\n",
            "Comparison with Class 12 Vector 3: 3 matching values\n",
            "Comparison with Class 12 Vector 4: 3 matching values\n",
            "Comparison with Class 12 Vector 5: 3 matching values\n",
            "Comparison with Class 12 Vector 6: 3 matching values\n",
            "Comparison with Class 12 Vector 7: 3 matching values\n",
            "Comparison with Class 12 Vector 8: 3 matching values\n",
            "Comparison with Class 12 Vector 9: 3 matching values\n",
            "Comparison with Class 12 Vector 10: 3 matching values\n",
            "Comparison with Class 12 Vector 11: 3 matching values\n",
            "Comparison with Class 12 Vector 12: 3 matching values\n",
            "Comparison with Class 12 Vector 13: 3 matching values\n",
            "Comparison with Class 12 Vector 14: 3 matching values\n",
            "Comparison with Class 12 Vector 15: 3 matching values\n",
            "Comparison with Class 12 Vector 16: 3 matching values\n",
            "Comparison with Class 12 Vector 17: 3 matching values\n",
            "Comparison with Class 12 Vector 18: 3 matching values\n",
            "Comparison with Class 12 Vector 19: 3 matching values\n",
            "\n",
            "Class 16:\n",
            "Comparison with Class 16 Vector 0: 3 matching values\n",
            "Comparison with Class 16 Vector 1: 3 matching values\n",
            "Comparison with Class 16 Vector 2: 3 matching values\n",
            "Comparison with Class 16 Vector 3: 3 matching values\n",
            "Comparison with Class 16 Vector 4: 3 matching values\n",
            "Comparison with Class 16 Vector 5: 3 matching values\n",
            "Comparison with Class 16 Vector 6: 3 matching values\n",
            "Comparison with Class 16 Vector 7: 2 matching values\n",
            "Comparison with Class 16 Vector 8: 3 matching values\n",
            "Comparison with Class 16 Vector 9: 2 matching values\n",
            "Comparison with Class 16 Vector 10: 3 matching values\n",
            "Comparison with Class 16 Vector 11: 3 matching values\n",
            "Comparison with Class 16 Vector 12: 3 matching values\n",
            "Comparison with Class 16 Vector 13: 3 matching values\n",
            "Comparison with Class 16 Vector 14: 3 matching values\n",
            "Comparison with Class 16 Vector 15: 3 matching values\n",
            "Comparison with Class 16 Vector 16: 3 matching values\n",
            "Comparison with Class 16 Vector 17: 3 matching values\n",
            "Comparison with Class 16 Vector 18: 3 matching values\n",
            "Comparison with Class 16 Vector 19: 3 matching values\n",
            "\n",
            "Class 15:\n",
            "Comparison with Class 15 Vector 0: 0 matching values\n",
            "Comparison with Class 15 Vector 1: 0 matching values\n",
            "Comparison with Class 15 Vector 2: 0 matching values\n",
            "Comparison with Class 15 Vector 3: 0 matching values\n",
            "Comparison with Class 15 Vector 4: 0 matching values\n",
            "Comparison with Class 15 Vector 5: 0 matching values\n",
            "Comparison with Class 15 Vector 6: 0 matching values\n",
            "Comparison with Class 15 Vector 7: 0 matching values\n",
            "Comparison with Class 15 Vector 8: 0 matching values\n",
            "Comparison with Class 15 Vector 9: 0 matching values\n",
            "Comparison with Class 15 Vector 10: 0 matching values\n",
            "Comparison with Class 15 Vector 11: 0 matching values\n",
            "Comparison with Class 15 Vector 12: 0 matching values\n",
            "Comparison with Class 15 Vector 13: 0 matching values\n",
            "Comparison with Class 15 Vector 14: 0 matching values\n",
            "Comparison with Class 15 Vector 15: 0 matching values\n",
            "Comparison with Class 15 Vector 16: 0 matching values\n",
            "Comparison with Class 15 Vector 17: 0 matching values\n",
            "Comparison with Class 15 Vector 18: 0 matching values\n",
            "Comparison with Class 15 Vector 19: 0 matching values\n",
            "\n",
            "Class 7:\n",
            "Comparison with Class 7 Vector 0: 0 matching values\n",
            "Comparison with Class 7 Vector 1: 0 matching values\n",
            "Comparison with Class 7 Vector 2: 0 matching values\n",
            "Comparison with Class 7 Vector 3: 0 matching values\n",
            "Comparison with Class 7 Vector 4: 0 matching values\n",
            "Comparison with Class 7 Vector 5: 0 matching values\n",
            "Comparison with Class 7 Vector 6: 0 matching values\n",
            "Comparison with Class 7 Vector 7: 0 matching values\n",
            "Comparison with Class 7 Vector 8: 0 matching values\n",
            "Comparison with Class 7 Vector 9: 0 matching values\n",
            "Comparison with Class 7 Vector 10: 0 matching values\n",
            "Comparison with Class 7 Vector 11: 0 matching values\n",
            "Comparison with Class 7 Vector 12: 0 matching values\n",
            "Comparison with Class 7 Vector 13: 0 matching values\n",
            "Comparison with Class 7 Vector 14: 0 matching values\n",
            "Comparison with Class 7 Vector 15: 0 matching values\n",
            "Comparison with Class 7 Vector 16: 0 matching values\n",
            "Comparison with Class 7 Vector 17: 0 matching values\n",
            "Comparison with Class 7 Vector 18: 0 matching values\n",
            "Comparison with Class 7 Vector 19: 0 matching values\n",
            "\n",
            "Class 6:\n",
            "Comparison with Class 6 Vector 0: 3 matching values\n",
            "Comparison with Class 6 Vector 1: 4 matching values\n",
            "Comparison with Class 6 Vector 2: 3 matching values\n",
            "Comparison with Class 6 Vector 3: 3 matching values\n",
            "Comparison with Class 6 Vector 4: 3 matching values\n",
            "Comparison with Class 6 Vector 5: 4 matching values\n",
            "Comparison with Class 6 Vector 6: 4 matching values\n",
            "Comparison with Class 6 Vector 7: 3 matching values\n",
            "Comparison with Class 6 Vector 8: 4 matching values\n",
            "Comparison with Class 6 Vector 9: 3 matching values\n",
            "Comparison with Class 6 Vector 10: 3 matching values\n",
            "Comparison with Class 6 Vector 11: 4 matching values\n",
            "Comparison with Class 6 Vector 12: 4 matching values\n",
            "Comparison with Class 6 Vector 13: 4 matching values\n",
            "Comparison with Class 6 Vector 14: 4 matching values\n",
            "Comparison with Class 6 Vector 15: 4 matching values\n",
            "Comparison with Class 6 Vector 16: 4 matching values\n",
            "Comparison with Class 6 Vector 17: 3 matching values\n",
            "Comparison with Class 6 Vector 18: 4 matching values\n",
            "Comparison with Class 6 Vector 19: 3 matching values\n",
            "\n",
            "Class 19:\n",
            "Comparison with Class 19 Vector 0: 1 matching values\n",
            "Comparison with Class 19 Vector 1: 1 matching values\n",
            "Comparison with Class 19 Vector 2: 1 matching values\n",
            "Comparison with Class 19 Vector 3: 1 matching values\n",
            "Comparison with Class 19 Vector 4: 1 matching values\n",
            "Comparison with Class 19 Vector 5: 1 matching values\n",
            "Comparison with Class 19 Vector 6: 1 matching values\n",
            "Comparison with Class 19 Vector 7: 1 matching values\n",
            "Comparison with Class 19 Vector 8: 0 matching values\n",
            "Comparison with Class 19 Vector 9: 1 matching values\n",
            "Comparison with Class 19 Vector 10: 1 matching values\n",
            "Comparison with Class 19 Vector 11: 1 matching values\n",
            "Comparison with Class 19 Vector 12: 1 matching values\n",
            "Comparison with Class 19 Vector 13: 1 matching values\n",
            "Comparison with Class 19 Vector 14: 1 matching values\n",
            "Comparison with Class 19 Vector 15: 1 matching values\n",
            "Comparison with Class 19 Vector 16: 1 matching values\n",
            "Comparison with Class 19 Vector 17: 1 matching values\n",
            "Comparison with Class 19 Vector 18: 1 matching values\n",
            "Comparison with Class 19 Vector 19: 1 matching values\n",
            "\n",
            "Class 18:\n",
            "Comparison with Class 18 Vector 0: 1 matching values\n",
            "Comparison with Class 18 Vector 1: 1 matching values\n",
            "Comparison with Class 18 Vector 2: 1 matching values\n",
            "Comparison with Class 18 Vector 3: 1 matching values\n",
            "Comparison with Class 18 Vector 4: 1 matching values\n",
            "Comparison with Class 18 Vector 5: 1 matching values\n",
            "Comparison with Class 18 Vector 6: 1 matching values\n",
            "Comparison with Class 18 Vector 7: 1 matching values\n",
            "Comparison with Class 18 Vector 8: 1 matching values\n",
            "Comparison with Class 18 Vector 9: 1 matching values\n",
            "Comparison with Class 18 Vector 10: 1 matching values\n",
            "Comparison with Class 18 Vector 11: 1 matching values\n",
            "Comparison with Class 18 Vector 12: 1 matching values\n",
            "Comparison with Class 18 Vector 13: 1 matching values\n",
            "Comparison with Class 18 Vector 14: 1 matching values\n",
            "Comparison with Class 18 Vector 15: 1 matching values\n",
            "Comparison with Class 18 Vector 16: 1 matching values\n",
            "Comparison with Class 18 Vector 17: 1 matching values\n",
            "Comparison with Class 18 Vector 18: 1 matching values\n",
            "Comparison with Class 18 Vector 19: 1 matching values\n",
            "\n",
            "Class 11:\n",
            "Comparison with Class 11 Vector 0: 1 matching values\n",
            "Comparison with Class 11 Vector 1: 1 matching values\n",
            "Comparison with Class 11 Vector 2: 1 matching values\n",
            "Comparison with Class 11 Vector 3: 1 matching values\n",
            "Comparison with Class 11 Vector 4: 1 matching values\n",
            "Comparison with Class 11 Vector 5: 1 matching values\n",
            "Comparison with Class 11 Vector 6: 1 matching values\n",
            "Comparison with Class 11 Vector 7: 1 matching values\n",
            "Comparison with Class 11 Vector 8: 1 matching values\n",
            "Comparison with Class 11 Vector 9: 1 matching values\n",
            "Comparison with Class 11 Vector 10: 1 matching values\n",
            "Comparison with Class 11 Vector 11: 1 matching values\n",
            "Comparison with Class 11 Vector 12: 1 matching values\n",
            "Comparison with Class 11 Vector 13: 1 matching values\n",
            "Comparison with Class 11 Vector 14: 1 matching values\n",
            "Comparison with Class 11 Vector 15: 1 matching values\n",
            "Comparison with Class 11 Vector 16: 1 matching values\n",
            "Comparison with Class 11 Vector 17: 1 matching values\n",
            "Comparison with Class 11 Vector 18: 1 matching values\n",
            "Comparison with Class 11 Vector 19: 1 matching values\n",
            "\n",
            "Class 2:\n",
            "Comparison with Class 2 Vector 0: 0 matching values\n",
            "Comparison with Class 2 Vector 1: 0 matching values\n",
            "Comparison with Class 2 Vector 2: 0 matching values\n",
            "Comparison with Class 2 Vector 3: 0 matching values\n",
            "Comparison with Class 2 Vector 4: 0 matching values\n",
            "Comparison with Class 2 Vector 5: 0 matching values\n",
            "Comparison with Class 2 Vector 6: 0 matching values\n",
            "Comparison with Class 2 Vector 7: 0 matching values\n",
            "Comparison with Class 2 Vector 8: 0 matching values\n",
            "Comparison with Class 2 Vector 9: 0 matching values\n",
            "Comparison with Class 2 Vector 10: 0 matching values\n",
            "Comparison with Class 2 Vector 11: 0 matching values\n",
            "Comparison with Class 2 Vector 12: 0 matching values\n",
            "Comparison with Class 2 Vector 13: 0 matching values\n",
            "Comparison with Class 2 Vector 14: 0 matching values\n",
            "Comparison with Class 2 Vector 15: 0 matching values\n",
            "Comparison with Class 2 Vector 16: 0 matching values\n",
            "Comparison with Class 2 Vector 17: 0 matching values\n",
            "Comparison with Class 2 Vector 18: 0 matching values\n",
            "Comparison with Class 2 Vector 19: 0 matching values\n",
            "\n",
            "Class 5:\n",
            "Comparison with Class 5 Vector 0: 2 matching values\n",
            "Comparison with Class 5 Vector 1: 2 matching values\n",
            "Comparison with Class 5 Vector 2: 2 matching values\n",
            "Comparison with Class 5 Vector 3: 2 matching values\n",
            "Comparison with Class 5 Vector 4: 2 matching values\n",
            "Comparison with Class 5 Vector 5: 2 matching values\n",
            "Comparison with Class 5 Vector 6: 2 matching values\n",
            "Comparison with Class 5 Vector 7: 2 matching values\n",
            "Comparison with Class 5 Vector 8: 2 matching values\n",
            "Comparison with Class 5 Vector 9: 2 matching values\n",
            "Comparison with Class 5 Vector 10: 2 matching values\n",
            "Comparison with Class 5 Vector 11: 2 matching values\n",
            "Comparison with Class 5 Vector 12: 2 matching values\n",
            "Comparison with Class 5 Vector 13: 2 matching values\n",
            "Comparison with Class 5 Vector 14: 2 matching values\n",
            "Comparison with Class 5 Vector 15: 2 matching values\n",
            "Comparison with Class 5 Vector 16: 2 matching values\n",
            "Comparison with Class 5 Vector 17: 2 matching values\n",
            "Comparison with Class 5 Vector 18: 2 matching values\n",
            "Comparison with Class 5 Vector 19: 2 matching values\n",
            "\n",
            "Class 21:\n",
            "Comparison with Class 21 Vector 0: 0 matching values\n",
            "Comparison with Class 21 Vector 1: 0 matching values\n",
            "Comparison with Class 21 Vector 2: 0 matching values\n",
            "Comparison with Class 21 Vector 3: 0 matching values\n",
            "Comparison with Class 21 Vector 4: 0 matching values\n",
            "Comparison with Class 21 Vector 5: 0 matching values\n",
            "Comparison with Class 21 Vector 6: 0 matching values\n",
            "Comparison with Class 21 Vector 7: 0 matching values\n",
            "Comparison with Class 21 Vector 8: 0 matching values\n",
            "Comparison with Class 21 Vector 9: 0 matching values\n",
            "Comparison with Class 21 Vector 10: 0 matching values\n",
            "Comparison with Class 21 Vector 11: 0 matching values\n",
            "Comparison with Class 21 Vector 12: 0 matching values\n",
            "Comparison with Class 21 Vector 13: 0 matching values\n",
            "Comparison with Class 21 Vector 14: 0 matching values\n",
            "Comparison with Class 21 Vector 15: 0 matching values\n",
            "Comparison with Class 21 Vector 16: 0 matching values\n",
            "Comparison with Class 21 Vector 17: 0 matching values\n",
            "Comparison with Class 21 Vector 18: 0 matching values\n",
            "Comparison with Class 21 Vector 19: 0 matching values\n",
            "\n",
            "Class 3:\n",
            "Comparison with Class 3 Vector 0: 3 matching values\n",
            "Comparison with Class 3 Vector 1: 1 matching values\n",
            "Comparison with Class 3 Vector 2: 1 matching values\n",
            "Comparison with Class 3 Vector 3: 1 matching values\n",
            "Comparison with Class 3 Vector 4: 1 matching values\n",
            "Comparison with Class 3 Vector 5: 2 matching values\n",
            "Comparison with Class 3 Vector 6: 2 matching values\n",
            "Comparison with Class 3 Vector 7: 2 matching values\n",
            "Comparison with Class 3 Vector 8: 1 matching values\n",
            "Comparison with Class 3 Vector 9: 1 matching values\n",
            "Comparison with Class 3 Vector 10: 2 matching values\n",
            "Comparison with Class 3 Vector 11: 1 matching values\n",
            "Comparison with Class 3 Vector 12: 2 matching values\n",
            "Comparison with Class 3 Vector 13: 2 matching values\n",
            "Comparison with Class 3 Vector 14: 3 matching values\n",
            "Comparison with Class 3 Vector 15: 2 matching values\n",
            "Comparison with Class 3 Vector 16: 3 matching values\n",
            "Comparison with Class 3 Vector 17: 3 matching values\n",
            "Comparison with Class 3 Vector 18: 1 matching values\n",
            "Comparison with Class 3 Vector 19: 3 matching values\n",
            "\n",
            "Class 1:\n",
            "Comparison with Class 1 Vector 0: 106 matching values\n",
            "Comparison with Class 1 Vector 1: 107 matching values\n",
            "Comparison with Class 1 Vector 2: 107 matching values\n",
            "Comparison with Class 1 Vector 3: 107 matching values\n",
            "Comparison with Class 1 Vector 4: 106 matching values\n",
            "Comparison with Class 1 Vector 5: 107 matching values\n",
            "Comparison with Class 1 Vector 6: 107 matching values\n",
            "Comparison with Class 1 Vector 7: 107 matching values\n",
            "Comparison with Class 1 Vector 8: 106 matching values\n",
            "Comparison with Class 1 Vector 9: 106 matching values\n",
            "Comparison with Class 1 Vector 10: 107 matching values\n",
            "Comparison with Class 1 Vector 11: 106 matching values\n",
            "Comparison with Class 1 Vector 12: 106 matching values\n",
            "Comparison with Class 1 Vector 13: 106 matching values\n",
            "Comparison with Class 1 Vector 14: 106 matching values\n",
            "Comparison with Class 1 Vector 15: 106 matching values\n",
            "Comparison with Class 1 Vector 16: 106 matching values\n",
            "Comparison with Class 1 Vector 17: 107 matching values\n",
            "Comparison with Class 1 Vector 18: 107 matching values\n",
            "Comparison with Class 1 Vector 19: 106 matching values\n",
            "\n",
            "Class 9:\n",
            "Comparison with Class 9 Vector 0: 128 matching values\n",
            "Comparison with Class 9 Vector 1: 127 matching values\n",
            "Comparison with Class 9 Vector 2: 128 matching values\n",
            "Comparison with Class 9 Vector 3: 127 matching values\n",
            "Comparison with Class 9 Vector 4: 128 matching values\n",
            "Comparison with Class 9 Vector 5: 127 matching values\n",
            "Comparison with Class 9 Vector 6: 127 matching values\n",
            "Comparison with Class 9 Vector 7: 127 matching values\n",
            "Comparison with Class 9 Vector 8: 127 matching values\n",
            "Comparison with Class 9 Vector 9: 127 matching values\n",
            "Comparison with Class 9 Vector 10: 127 matching values\n",
            "Comparison with Class 9 Vector 11: 127 matching values\n",
            "Comparison with Class 9 Vector 12: 128 matching values\n",
            "Comparison with Class 9 Vector 13: 127 matching values\n",
            "Comparison with Class 9 Vector 14: 127 matching values\n",
            "Comparison with Class 9 Vector 15: 128 matching values\n",
            "Comparison with Class 9 Vector 16: 127 matching values\n",
            "Comparison with Class 9 Vector 17: 128 matching values\n",
            "Comparison with Class 9 Vector 18: 127 matching values\n",
            "Comparison with Class 9 Vector 19: 127 matching values\n",
            "\n",
            "Class 0:\n",
            "Comparison with Class 0 Vector 0: 0 matching values\n",
            "Comparison with Class 0 Vector 1: 0 matching values\n",
            "Comparison with Class 0 Vector 2: 0 matching values\n",
            "Comparison with Class 0 Vector 3: 0 matching values\n",
            "Comparison with Class 0 Vector 4: 0 matching values\n",
            "Comparison with Class 0 Vector 5: 0 matching values\n",
            "Comparison with Class 0 Vector 6: 0 matching values\n",
            "Comparison with Class 0 Vector 7: 0 matching values\n",
            "Comparison with Class 0 Vector 8: 0 matching values\n",
            "Comparison with Class 0 Vector 9: 0 matching values\n",
            "Comparison with Class 0 Vector 10: 0 matching values\n",
            "Comparison with Class 0 Vector 11: 0 matching values\n",
            "Comparison with Class 0 Vector 12: 0 matching values\n",
            "Comparison with Class 0 Vector 13: 0 matching values\n",
            "Comparison with Class 0 Vector 14: 0 matching values\n",
            "Comparison with Class 0 Vector 15: 0 matching values\n",
            "Comparison with Class 0 Vector 16: 0 matching values\n",
            "Comparison with Class 0 Vector 17: 0 matching values\n",
            "Comparison with Class 0 Vector 18: 0 matching values\n",
            "Comparison with Class 0 Vector 19: 0 matching values\n",
            "\n",
            "Class 4:\n",
            "Comparison with Class 4 Vector 0: 0 matching values\n",
            "Comparison with Class 4 Vector 1: 0 matching values\n",
            "Comparison with Class 4 Vector 2: 0 matching values\n",
            "Comparison with Class 4 Vector 3: 0 matching values\n",
            "Comparison with Class 4 Vector 4: 0 matching values\n",
            "Comparison with Class 4 Vector 5: 0 matching values\n",
            "Comparison with Class 4 Vector 6: 0 matching values\n",
            "Comparison with Class 4 Vector 7: 0 matching values\n",
            "Comparison with Class 4 Vector 8: 0 matching values\n",
            "Comparison with Class 4 Vector 9: 0 matching values\n",
            "Comparison with Class 4 Vector 10: 0 matching values\n",
            "Comparison with Class 4 Vector 11: 0 matching values\n",
            "Comparison with Class 4 Vector 12: 0 matching values\n",
            "Comparison with Class 4 Vector 13: 0 matching values\n",
            "Comparison with Class 4 Vector 14: 0 matching values\n",
            "Comparison with Class 4 Vector 15: 0 matching values\n",
            "Comparison with Class 4 Vector 16: 0 matching values\n",
            "Comparison with Class 4 Vector 17: 0 matching values\n",
            "Comparison with Class 4 Vector 18: 0 matching values\n",
            "Comparison with Class 4 Vector 19: 0 matching values\n",
            "\n",
            "Class 22:\n",
            "Comparison with Class 22 Vector 0: 0 matching values\n",
            "Comparison with Class 22 Vector 1: 0 matching values\n",
            "Comparison with Class 22 Vector 2: 0 matching values\n",
            "Comparison with Class 22 Vector 3: 0 matching values\n",
            "Comparison with Class 22 Vector 4: 0 matching values\n",
            "Comparison with Class 22 Vector 5: 0 matching values\n",
            "Comparison with Class 22 Vector 6: 0 matching values\n",
            "Comparison with Class 22 Vector 7: 0 matching values\n",
            "Comparison with Class 22 Vector 8: 0 matching values\n",
            "Comparison with Class 22 Vector 9: 0 matching values\n",
            "Comparison with Class 22 Vector 10: 0 matching values\n",
            "Comparison with Class 22 Vector 11: 0 matching values\n",
            "Comparison with Class 22 Vector 12: 0 matching values\n",
            "Comparison with Class 22 Vector 13: 0 matching values\n",
            "Comparison with Class 22 Vector 14: 0 matching values\n",
            "Comparison with Class 22 Vector 15: 0 matching values\n",
            "Comparison with Class 22 Vector 16: 0 matching values\n",
            "Comparison with Class 22 Vector 17: 0 matching values\n",
            "Comparison with Class 22 Vector 18: 0 matching values\n",
            "Comparison with Class 22 Vector 19: 0 matching values\n",
            "\n",
            "Class 14:\n",
            "Comparison with Class 14 Vector 0: 0 matching values\n",
            "Comparison with Class 14 Vector 1: 0 matching values\n",
            "Comparison with Class 14 Vector 2: 0 matching values\n",
            "Comparison with Class 14 Vector 3: 0 matching values\n",
            "Comparison with Class 14 Vector 4: 0 matching values\n",
            "Comparison with Class 14 Vector 5: 0 matching values\n",
            "Comparison with Class 14 Vector 6: 0 matching values\n",
            "Comparison with Class 14 Vector 7: 0 matching values\n",
            "Comparison with Class 14 Vector 8: 0 matching values\n",
            "Comparison with Class 14 Vector 9: 0 matching values\n",
            "Comparison with Class 14 Vector 10: 0 matching values\n",
            "Comparison with Class 14 Vector 11: 0 matching values\n",
            "Comparison with Class 14 Vector 12: 0 matching values\n",
            "Comparison with Class 14 Vector 13: 0 matching values\n",
            "Comparison with Class 14 Vector 14: 0 matching values\n",
            "Comparison with Class 14 Vector 15: 0 matching values\n",
            "Comparison with Class 14 Vector 16: 0 matching values\n",
            "Comparison with Class 14 Vector 17: 0 matching values\n",
            "Comparison with Class 14 Vector 18: 0 matching values\n",
            "Comparison with Class 14 Vector 19: 0 matching values\n",
            "\n",
            "Class 10:\n",
            "Comparison with Class 10 Vector 0: 1 matching values\n",
            "Comparison with Class 10 Vector 1: 1 matching values\n",
            "Comparison with Class 10 Vector 2: 1 matching values\n",
            "Comparison with Class 10 Vector 3: 1 matching values\n",
            "Comparison with Class 10 Vector 4: 1 matching values\n",
            "Comparison with Class 10 Vector 5: 1 matching values\n",
            "Comparison with Class 10 Vector 6: 1 matching values\n",
            "Comparison with Class 10 Vector 7: 1 matching values\n",
            "Comparison with Class 10 Vector 8: 1 matching values\n",
            "Comparison with Class 10 Vector 9: 1 matching values\n",
            "Comparison with Class 10 Vector 10: 1 matching values\n",
            "Comparison with Class 10 Vector 11: 1 matching values\n",
            "Comparison with Class 10 Vector 12: 1 matching values\n",
            "Comparison with Class 10 Vector 13: 1 matching values\n",
            "Comparison with Class 10 Vector 14: 1 matching values\n",
            "Comparison with Class 10 Vector 15: 1 matching values\n",
            "Comparison with Class 10 Vector 16: 1 matching values\n",
            "Comparison with Class 10 Vector 17: 1 matching values\n",
            "Comparison with Class 10 Vector 18: 1 matching values\n",
            "Comparison with Class 10 Vector 19: 1 matching values\n",
            "\n",
            "Class 8:\n",
            "Comparison with Class 8 Vector 0: 0 matching values\n",
            "Comparison with Class 8 Vector 1: 0 matching values\n",
            "Comparison with Class 8 Vector 2: 0 matching values\n",
            "Comparison with Class 8 Vector 3: 0 matching values\n",
            "Comparison with Class 8 Vector 4: 0 matching values\n",
            "Comparison with Class 8 Vector 5: 0 matching values\n",
            "Comparison with Class 8 Vector 6: 0 matching values\n",
            "Comparison with Class 8 Vector 7: 0 matching values\n",
            "Comparison with Class 8 Vector 8: 0 matching values\n",
            "Comparison with Class 8 Vector 9: 0 matching values\n",
            "Comparison with Class 8 Vector 10: 0 matching values\n",
            "Comparison with Class 8 Vector 11: 0 matching values\n",
            "Comparison with Class 8 Vector 12: 0 matching values\n",
            "Comparison with Class 8 Vector 13: 0 matching values\n",
            "Comparison with Class 8 Vector 14: 0 matching values\n",
            "Comparison with Class 8 Vector 15: 0 matching values\n",
            "Comparison with Class 8 Vector 16: 0 matching values\n",
            "Comparison with Class 8 Vector 17: 0 matching values\n",
            "Comparison with Class 8 Vector 18: 0 matching values\n",
            "Comparison with Class 8 Vector 19: 0 matching values\n",
            "\n",
            "Class 17:\n",
            "Comparison with Class 17 Vector 0: 2 matching values\n",
            "Comparison with Class 17 Vector 1: 2 matching values\n",
            "Comparison with Class 17 Vector 2: 2 matching values\n",
            "Comparison with Class 17 Vector 3: 2 matching values\n",
            "Comparison with Class 17 Vector 4: 2 matching values\n",
            "Comparison with Class 17 Vector 5: 2 matching values\n",
            "Comparison with Class 17 Vector 6: 2 matching values\n",
            "Comparison with Class 17 Vector 7: 2 matching values\n",
            "Comparison with Class 17 Vector 8: 2 matching values\n",
            "Comparison with Class 17 Vector 9: 2 matching values\n",
            "Comparison with Class 17 Vector 10: 2 matching values\n",
            "Comparison with Class 17 Vector 11: 2 matching values\n",
            "Comparison with Class 17 Vector 12: 2 matching values\n",
            "Comparison with Class 17 Vector 13: 2 matching values\n",
            "Comparison with Class 17 Vector 14: 2 matching values\n",
            "Comparison with Class 17 Vector 15: 2 matching values\n",
            "Comparison with Class 17 Vector 16: 2 matching values\n",
            "Comparison with Class 17 Vector 17: 2 matching values\n",
            "Comparison with Class 17 Vector 18: 2 matching values\n",
            "Comparison with Class 17 Vector 19: 2 matching values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----------------"
      ],
      "metadata": {
        "id": "0SkoTGh2QXmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from deepface import DeepFace\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def normalize_brightness_contrast_grayscale(image):\n",
        "    # Normalize brightness using LAB color space\n",
        "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    l = cv2.equalizeHist(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Contrast normalization using CLAHE\n",
        "    lab = cv2.cvtColor(normalized_image, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    l = clahe.apply(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    normalized_contrast_image = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray_image = cv2.cvtColor(normalized_contrast_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    return gray_image\n",
        "\n",
        "# Block 1: Code for Loading the Model\n",
        "model.load_state_dict(torch.load(lstm_no_aug_path))\n",
        "model.eval()\n",
        "\n",
        "def get_lengths(batch_size):\n",
        "    return torch.ones(batch_size, dtype=torch.long)\n",
        "\n",
        "# Block 2: Code for Getting Image Embedding (Preprocessing Integrated)\n",
        "def get_initial_image_embedding(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Apply preprocessing\n",
        "    gray_image = normalize_brightness_contrast_grayscale(image)\n",
        "\n",
        "    # Since DeepFace expects a 3-channel image, convert grayscale to RGB\n",
        "    image_rgb = cv2.cvtColor(gray_image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    embedding = DeepFace.represent(img_path=image_rgb, model_name=\"Facenet512\", detector_backend='skip')\n",
        "    embarr = np.array(embedding[0][\"embedding\"])\n",
        "    return torch.tensor(embarr, dtype=torch.float32).unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "def get_final_image_embedding(image_path, model):\n",
        "    initial_embedding = get_initial_image_embedding(image_path)\n",
        "    lengths = torch.tensor([initial_embedding.shape[1]])  # Sequence length is 1\n",
        "    with torch.no_grad():\n",
        "        final_embedding = model(initial_embedding, lengths)\n",
        "    return final_embedding\n",
        "\n",
        "# Block 3: Code for Comparing Embeddings\n",
        "def compare_with_tolerance(embedding1, embedding2, tolerance=0.1):\n",
        "    return torch.sum(torch.abs(embedding1 - embedding2) <= tolerance).item()\n",
        "\n",
        "def compare_embeddings_in_folder(folder_path, model, tolerance=0.1):\n",
        "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))])[:10]  # Take first 20 images\n",
        "    embeddings = []\n",
        "    count_128_matches = 0  # Initialize a counter for 128 matching values\n",
        "\n",
        "    # Compute embeddings for the selected images\n",
        "    for image_file in image_files:\n",
        "        image_path = os.path.join(folder_path, image_file)\n",
        "        final_embedding = get_final_image_embedding(image_path, model)\n",
        "        final_embedding_rounded = torch.round(final_embedding)\n",
        "        embeddings.append((image_file, final_embedding_rounded))\n",
        "\n",
        "    # Print all embeddings\n",
        "    print(\"\\nTest Image Embeddings:\")\n",
        "    for image_file, embedding in embeddings:\n",
        "        print(f\"\\nImage: {image_file}\")\n",
        "        print(embedding.squeeze().numpy())\n",
        "\n",
        "    # Compare embeddings with each other\n",
        "    print(\"\\nComparisons Between Test Image Embeddings:\")\n",
        "    for i in range(len(embeddings)):\n",
        "        for j in range(i + 1, len(embeddings)):\n",
        "            image_file_i, embedding_i = embeddings[i]\n",
        "            image_file_j, embedding_j = embeddings[j]\n",
        "            matching_count = compare_with_tolerance(embedding_i, embedding_j, tolerance)\n",
        "\n",
        "            if matching_count == 128:\n",
        "                count_128_matches += 1  # Increment the counter if 128 matching values are found\n",
        "\n",
        "            print(f\"\\nComparison between {image_file_i} and {image_file_j}: {matching_count} matching values\")\n",
        "\n",
        "    # Print the final count of 128 matching values\n",
        "    print(f\"\\nNumber of comparisons with exactly 128 matching values: {count_128_matches}\")\n",
        "\n",
        "# Specify the folder containing images\n",
        "folder_path = '/content/drive/MyDrive/28thnight/FaceScan_D8_no_bg2/Test/Shubham'  # change this\n",
        "compare_embeddings_in_folder(folder_path, model)\n",
        "/content/drive/MyDrive/28thnight/FaceScan_D8_no_bg2/Test/Ajay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCIUSzqBMZ9o",
        "outputId": "b2bdf70b-18c4-4a61-a864-cd5614b5fca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Image Embeddings:\n",
            "\n",
            "Image: 20240817_165402.jpg\n",
            "[-1. -4.  1.  9. -1. -4. -2. -2. -1. -5. -3.  2. -3.  3. -1. -4.  3. -4.\n",
            " -4. -2. -5. -4.  1. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.\n",
            " -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.\n",
            " -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.\n",
            " -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.\n",
            " -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5.\n",
            " -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -5. -4. -5. -5.\n",
            " -5. -5.]\n",
            "\n",
            "Image: 20240817_165403.jpg\n",
            "[-2. -4. -1.  7. -0. -3. -2. -2. -1. -4. -3.  1. -2.  5. -1. -3.  3. -4.\n",
            " -4. -1. -4. -4.  1. -4. -4. -5. -4. -4. -5. -5. -5. -5. -5. -5. -4. -5.\n",
            " -5. -4. -5. -5. -5. -4. -5. -4. -4. -5. -4. -5. -4. -4. -5. -5. -5. -4.\n",
            " -5. -4. -5. -5. -4. -4. -5. -4. -4. -5. -5. -5. -4. -4. -5. -4. -5. -4.\n",
            " -4. -4. -5. -4. -4. -4. -5. -5. -4. -4. -5. -5. -4. -4. -4. -4. -4. -5.\n",
            " -5. -4. -4. -5. -5. -4. -4. -4. -4. -5. -5. -5. -4. -5. -5. -4. -5. -4.\n",
            " -5. -5. -4. -5. -4. -4. -5. -4. -4. -4. -4. -5. -5. -4. -5. -4. -5. -5.\n",
            " -5. -5.]\n",
            "\n",
            "Image: 20240817_165404.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -6. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165405.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -6. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165406.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -5. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165407.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  0. -3.  5. -6. -2.  1.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165408.jpg\n",
            "[ 4.  1.  9.  5. -4. -5.  2. -0. -3. -5. -3. -2. -2. -4. -2. -3.  2. -4.\n",
            " -4. -3. -4. -4. -2. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4.\n",
            " -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4.\n",
            " -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4.\n",
            " -4. -4. -4. -4. -4. -4. -4. -5. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4.\n",
            " -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -5. -4.\n",
            " -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4. -4.\n",
            " -4. -4.]\n",
            "\n",
            "Image: 20240817_165412.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -6. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -1. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165414.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -5. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Image: 20240817_165415.jpg\n",
            "[ 4. 17.  5. -0. -2. -3.  4. -1. -3.  5.  1. -3.  5. -6. -2.  0.  1.  1.\n",
            " -1. -0.  0.  1. -1. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0.  0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0. -0.\n",
            " -0. -0.]\n",
            "\n",
            "Comparisons Between Test Image Embeddings:\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165403.jpg: 65 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165404.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165405.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165406.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165407.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165408.jpg: 8 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165412.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165414.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165402.jpg and 20240817_165415.jpg: 0 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165404.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165405.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165406.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165407.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165408.jpg: 61 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165412.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165414.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165403.jpg and 20240817_165415.jpg: 1 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165405.jpg: 128 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165406.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165407.jpg: 125 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165408.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165412.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165414.jpg: 126 matching values\n",
            "\n",
            "Comparison between 20240817_165404.jpg and 20240817_165415.jpg: 128 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165406.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165407.jpg: 125 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165408.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165412.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165414.jpg: 126 matching values\n",
            "\n",
            "Comparison between 20240817_165405.jpg and 20240817_165415.jpg: 128 matching values\n",
            "\n",
            "Comparison between 20240817_165406.jpg and 20240817_165407.jpg: 124 matching values\n",
            "\n",
            "Comparison between 20240817_165406.jpg and 20240817_165408.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165406.jpg and 20240817_165412.jpg: 126 matching values\n",
            "\n",
            "Comparison between 20240817_165406.jpg and 20240817_165414.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165406.jpg and 20240817_165415.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165407.jpg and 20240817_165408.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165407.jpg and 20240817_165412.jpg: 126 matching values\n",
            "\n",
            "Comparison between 20240817_165407.jpg and 20240817_165414.jpg: 125 matching values\n",
            "\n",
            "Comparison between 20240817_165407.jpg and 20240817_165415.jpg: 125 matching values\n",
            "\n",
            "Comparison between 20240817_165408.jpg and 20240817_165412.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165408.jpg and 20240817_165414.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165408.jpg and 20240817_165415.jpg: 3 matching values\n",
            "\n",
            "Comparison between 20240817_165412.jpg and 20240817_165414.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165412.jpg and 20240817_165415.jpg: 127 matching values\n",
            "\n",
            "Comparison between 20240817_165414.jpg and 20240817_165415.jpg: 126 matching values\n",
            "\n",
            "Number of comparisons with exactly 128 matching values: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4tHqBFpVMfsP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}